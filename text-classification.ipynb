{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30683,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Text classification\n\nDate : 10-04-2024","metadata":{}},{"cell_type":"markdown","source":"* Text classification is a common NLP task that assigns a label or class to text\n* One of the most popular forms of text classification is sentiment analysis, which assigns a label like  positive,  negative, or  neutral to a sequence of text","metadata":{}},{"cell_type":"code","source":"pip install transformers datasets evaluate accelerate","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-04-10T11:38:37.522515Z","iopub.execute_input":"2024-04-10T11:38:37.522878Z","iopub.status.idle":"2024-04-10T11:38:51.614539Z","shell.execute_reply.started":"2024-04-10T11:38:37.522850Z","shell.execute_reply":"2024-04-10T11:38:51.613246Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.39.3)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.18.0)\nCollecting evaluate\n  Downloading evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.28.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.22.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.2)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (15.0.2)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.1.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets) (2024.2.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\nCollecting responses<0.19 (from evaluate)\n  Downloading responses-0.18.0-py3-none-any.whl.metadata (29 kB)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.1.2)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\nDownloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading responses-0.18.0-py3-none-any.whl (38 kB)\nInstalling collected packages: responses, evaluate\nSuccessfully installed evaluate-0.4.1 responses-0.18.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"\nfrom kaggle_secrets import UserSecretsClient\nhuggingface_token = UserSecretsClient().get_secret(\"huggingface_token\")","metadata":{"execution":{"iopub.status.busy":"2024-04-10T11:38:51.616506Z","iopub.execute_input":"2024-04-10T11:38:51.616829Z","iopub.status.idle":"2024-04-10T11:38:51.751433Z","shell.execute_reply.started":"2024-04-10T11:38:51.616799Z","shell.execute_reply":"2024-04-10T11:38:51.750746Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import login\n\nlogin(token=huggingface_token)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-10T11:38:51.752375Z","iopub.execute_input":"2024-04-10T11:38:51.752624Z","iopub.status.idle":"2024-04-10T11:38:52.222989Z","shell.execute_reply.started":"2024-04-10T11:38:51.752601Z","shell.execute_reply":"2024-04-10T11:38:52.222024Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\nToken is valid (permission: write).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\n\n# # Check if a GPU is available and if not, use a CPU\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2024-04-10T11:38:52.225691Z","iopub.execute_input":"2024-04-10T11:38:52.226135Z","iopub.status.idle":"2024-04-10T11:38:55.454431Z","shell.execute_reply.started":"2024-04-10T11:38:52.226101Z","shell.execute_reply":"2024-04-10T11:38:55.453611Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"**Load IMDb dataset**","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\n\nimdb = load_dataset(\"imdb\")\nimdb","metadata":{"execution":{"iopub.status.busy":"2024-04-10T11:38:55.455704Z","iopub.execute_input":"2024-04-10T11:38:55.456316Z","iopub.status.idle":"2024-04-10T11:39:05.783442Z","shell.execute_reply.started":"2024-04-10T11:38:55.456278Z","shell.execute_reply":"2024-04-10T11:39:05.782352Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/7.81k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5443d569923d487ca1cd5fe6b7ca63c1"}},"metadata":{}},{"name":"stderr","text":"Downloading data: 100%|| 21.0M/21.0M [00:00<00:00, 57.3MB/s]\nDownloading data: 100%|| 20.5M/20.5M [00:00<00:00, 34.6MB/s]\nDownloading data: 100%|| 42.0M/42.0M [00:00<00:00, 128MB/s] \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b4db6d0267dc43fc9b3735b5d44f72f1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/25000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"625af8011b81445bbc56bf4ad6c0e33a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating unsupervised split:   0%|          | 0/50000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cecd747939914bb3a78e93a0c893bb38"}},"metadata":{}},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'label'],\n        num_rows: 25000\n    })\n    test: Dataset({\n        features: ['text', 'label'],\n        num_rows: 25000\n    })\n    unsupervised: Dataset({\n        features: ['text', 'label'],\n        num_rows: 50000\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"imdb.pop('unsupervised')\nimdb","metadata":{"execution":{"iopub.status.busy":"2024-04-10T11:39:05.784915Z","iopub.execute_input":"2024-04-10T11:39:05.785535Z","iopub.status.idle":"2024-04-10T11:39:05.792341Z","shell.execute_reply.started":"2024-04-10T11:39:05.785497Z","shell.execute_reply":"2024-04-10T11:39:05.791358Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'label'],\n        num_rows: 25000\n    })\n    test: Dataset({\n        features: ['text', 'label'],\n        num_rows: 25000\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"from datasets import concatenate_datasets\n\nimdb = concatenate_datasets([imdb['train'], imdb['test']])\nimdb","metadata":{"execution":{"iopub.status.busy":"2024-04-10T11:39:05.793820Z","iopub.execute_input":"2024-04-10T11:39:05.794521Z","iopub.status.idle":"2024-04-10T11:39:06.060179Z","shell.execute_reply.started":"2024-04-10T11:39:05.794485Z","shell.execute_reply":"2024-04-10T11:39:06.059186Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['text', 'label'],\n    num_rows: 50000\n})"},"metadata":{}}]},{"cell_type":"code","source":"imdb.push_to_hub(\"vishnun0027/imdb_dataset\", private=False)","metadata":{"execution":{"iopub.status.busy":"2024-04-10T11:39:06.061482Z","iopub.execute_input":"2024-04-10T11:39:06.061858Z","iopub.status.idle":"2024-04-10T11:39:08.991398Z","shell.execute_reply.started":"2024-04-10T11:39:06.061823Z","shell.execute_reply":"2024-04-10T11:39:08.990410Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd402c63caca4297a8e8cf4f9851ef1d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Creating parquet from Arrow format:   0%|          | 0/50 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"96d3141b9fbf48fc8aa38e796afff47a"}},"metadata":{}},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/datasets/vishnun0027/imdb_dataset/commit/8e18916dae8ecff0e9dbd6fd576a4cb65bda96bf', commit_message='Upload dataset', commit_description='', oid='8e18916dae8ecff0e9dbd6fd576a4cb65bda96bf', pr_url=None, pr_revision=None, pr_num=None)"},"metadata":{}}]},{"cell_type":"code","source":"imdb = imdb.train_test_split(test_size=0.2)","metadata":{"execution":{"iopub.status.busy":"2024-04-10T11:39:08.992743Z","iopub.execute_input":"2024-04-10T11:39:08.993219Z","iopub.status.idle":"2024-04-10T11:39:09.036426Z","shell.execute_reply.started":"2024-04-10T11:39:08.993183Z","shell.execute_reply":"2024-04-10T11:39:09.035648Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"imdb","metadata":{"execution":{"iopub.status.busy":"2024-04-10T11:39:09.039797Z","iopub.execute_input":"2024-04-10T11:39:09.040183Z","iopub.status.idle":"2024-04-10T11:39:09.046197Z","shell.execute_reply.started":"2024-04-10T11:39:09.040144Z","shell.execute_reply":"2024-04-10T11:39:09.045246Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'label'],\n        num_rows: 40000\n    })\n    test: Dataset({\n        features: ['text', 'label'],\n        num_rows: 10000\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"imdb[\"test\"][100]","metadata":{"execution":{"iopub.status.busy":"2024-04-10T11:39:09.047244Z","iopub.execute_input":"2024-04-10T11:39:09.047512Z","iopub.status.idle":"2024-04-10T11:39:09.061834Z","shell.execute_reply.started":"2024-04-10T11:39:09.047488Z","shell.execute_reply":"2024-04-10T11:39:09.060790Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"{'text': \"The original Lensman series of novels is a classic of the genre. It's pure adventure SF with some substance (here and there) and I've always wondered why Hollywood hasn't filmed it verbatim because it's just the kind of thing they love: massive explosions, super-weapons, uber-heroics, hero gets the girl, aliens (great CGI potential), good versus evil in the purest form, etc etc. Instead (and bear in mind I'm a Japan-o-phile and anime lover) we get this horrendous kiddies movie that rips the guts out of the story, mixes in Star-Wars (ironic as the latter ripped off the books occasionally) pastiches and dumbs the whole thing down to 'Thundercats' level. To see Kimball Kinnison, the epitome of the Galactic Patrol officer and second stage Lensman portrayed as a small boy is pitiful (etc). I just can't understand why the makers did this because they obviously had the rights to the story and could have made far more money (FAR!) by telling straight. It makes no sense.\",\n 'label': 0}"},"metadata":{}}]},{"cell_type":"markdown","source":"**Preprocess**","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")","metadata":{"execution":{"iopub.status.busy":"2024-04-10T11:39:09.063246Z","iopub.execute_input":"2024-04-10T11:39:09.063535Z","iopub.status.idle":"2024-04-10T11:39:11.401029Z","shell.execute_reply.started":"2024-04-10T11:39:09.063511Z","shell.execute_reply":"2024-04-10T11:39:11.400039Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d36630ee2ee242f987ee48b100ca1d83"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e6cb21a935ba4186a08be73435968f82"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8447e22a03ca43e08d842e87be71461a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f3406928fba4a63b6bb39f085ca89b6"}},"metadata":{}}]},{"cell_type":"code","source":"def preprocess_function(examples):\n    return tokenizer(examples[\"text\"],max_length=512,truncation=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-10T11:39:11.402293Z","iopub.execute_input":"2024-04-10T11:39:11.402724Z","iopub.status.idle":"2024-04-10T11:39:11.407950Z","shell.execute_reply.started":"2024-04-10T11:39:11.402700Z","shell.execute_reply":"2024-04-10T11:39:11.406712Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"tokenized_imdb = imdb.map(preprocess_function, batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-10T11:39:11.409344Z","iopub.execute_input":"2024-04-10T11:39:11.409699Z","iopub.status.idle":"2024-04-10T11:39:40.343088Z","shell.execute_reply.started":"2024-04-10T11:39:11.409662Z","shell.execute_reply":"2024-04-10T11:39:40.342112Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/40000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b917dddfe7a4c93afcb5f58a1067c18"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5700148cb054fc2b6e5e3985c578b95"}},"metadata":{}}]},{"cell_type":"code","source":"from transformers import DataCollatorWithPadding\n\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-04-10T11:39:40.344290Z","iopub.execute_input":"2024-04-10T11:39:40.344578Z","iopub.status.idle":"2024-04-10T11:39:49.838808Z","shell.execute_reply.started":"2024-04-10T11:39:40.344554Z","shell.execute_reply":"2024-04-10T11:39:49.838017Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"2024-04-10 11:39:42.472267: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-10 11:39:42.472369: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-10 11:39:42.573843: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Evaluate**","metadata":{}},{"cell_type":"code","source":"import evaluate\n\naccuracy = evaluate.load(\"accuracy\")","metadata":{"execution":{"iopub.status.busy":"2024-04-10T11:39:49.839809Z","iopub.execute_input":"2024-04-10T11:39:49.840376Z","iopub.status.idle":"2024-04-10T11:39:51.468216Z","shell.execute_reply.started":"2024-04-10T11:39:49.840348Z","shell.execute_reply":"2024-04-10T11:39:51.467414Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"387303b0a0814fa2a041a18d133d68a1"}},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\n\n\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    predictions = np.argmax(predictions, axis=1)\n    return accuracy.compute(predictions=predictions, references=labels)","metadata":{"execution":{"iopub.status.busy":"2024-04-10T11:39:51.469281Z","iopub.execute_input":"2024-04-10T11:39:51.469552Z","iopub.status.idle":"2024-04-10T11:39:51.474590Z","shell.execute_reply.started":"2024-04-10T11:39:51.469528Z","shell.execute_reply":"2024-04-10T11:39:51.473538Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"**Train**","metadata":{}},{"cell_type":"code","source":"id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\nlabel2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}","metadata":{"execution":{"iopub.status.busy":"2024-04-10T11:39:51.475877Z","iopub.execute_input":"2024-04-10T11:39:51.476219Z","iopub.status.idle":"2024-04-10T11:39:51.484046Z","shell.execute_reply.started":"2024-04-10T11:39:51.476192Z","shell.execute_reply":"2024-04-10T11:39:51.483089Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    \"distilbert/distilbert-base-uncased\", num_labels=2, id2label=id2label, label2id=label2id\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-10T11:39:51.485480Z","iopub.execute_input":"2024-04-10T11:39:51.486242Z","iopub.status.idle":"2024-04-10T11:39:53.411018Z","shell.execute_reply.started":"2024-04-10T11:39:51.486207Z","shell.execute_reply":"2024-04-10T11:39:53.410076Z"},"trusted":true},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ed3026e3790472282dc3208c1831bb2"}},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"vishnun0027/Text_classification_model_10042024\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    num_train_epochs=3,\n    weight_decay=0.01,\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True,\n    push_to_hub=True,\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_imdb[\"train\"],\n    eval_dataset=tokenized_imdb[\"test\"],\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)\n\ntrainer.train()\ntrainer.push_to_hub()","metadata":{"execution":{"iopub.status.busy":"2024-04-10T11:39:53.412356Z","iopub.execute_input":"2024-04-10T11:39:53.412665Z","iopub.status.idle":"2024-04-10T12:37:40.948197Z","shell.execute_reply.started":"2024-04-10T11:39:53.412639Z","shell.execute_reply":"2024-04-10T12:37:40.946804Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n  warnings.warn(\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.16.6 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.5"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240410_114006-023j866i</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/vishnun0027/huggingface/runs/023j866i/workspace' target=\"_blank\">lucky-haze-9</a></strong> to <a href='https://wandb.ai/vishnun0027/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/vishnun0027/huggingface' target=\"_blank\">https://wandb.ai/vishnun0027/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/vishnun0027/huggingface/runs/023j866i/workspace' target=\"_blank\">https://wandb.ai/vishnun0027/huggingface/runs/023j866i/workspace</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3750' max='3750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3750/3750 56:57, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.212500</td>\n      <td>0.183901</td>\n      <td>0.930700</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.131800</td>\n      <td>0.180242</td>\n      <td>0.936600</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.076200</td>\n      <td>0.228744</td>\n      <td>0.937300</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/vishnun0027/Text_classification_model_10042024/commit/c0f4fa9ca9ed1a4fd1ce7c6607948c744e21cb31', commit_message='End of training', commit_description='', oid='c0f4fa9ca9ed1a4fd1ce7c6607948c744e21cb31', pr_url=None, pr_revision=None, pr_num=None)"},"metadata":{}}]},{"cell_type":"markdown","source":"**Inference**","metadata":{}},{"cell_type":"code","source":"import torch","metadata":{"execution":{"iopub.status.busy":"2024-04-10T12:37:40.949493Z","iopub.execute_input":"2024-04-10T12:37:40.949803Z","iopub.status.idle":"2024-04-10T12:37:40.955213Z","shell.execute_reply.started":"2024-04-10T12:37:40.949777Z","shell.execute_reply":"2024-04-10T12:37:40.953963Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"text = \"This was a masterpiece. Not completely faithful to the books, but enthralling from beginning to end. Might be my favorite of the three.\"","metadata":{"execution":{"iopub.status.busy":"2024-04-10T12:37:40.956701Z","iopub.execute_input":"2024-04-10T12:37:40.957721Z","iopub.status.idle":"2024-04-10T12:37:40.964042Z","shell.execute_reply.started":"2024-04-10T12:37:40.957683Z","shell.execute_reply":"2024-04-10T12:37:40.963029Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"vishnun0027/Text_classification_model_10042024\")\ninputs = tokenizer(text, return_tensors=\"pt\")","metadata":{"execution":{"iopub.status.busy":"2024-04-10T12:37:40.965447Z","iopub.execute_input":"2024-04-10T12:37:40.966757Z","iopub.status.idle":"2024-04-10T12:37:40.991674Z","shell.execute_reply.started":"2024-04-10T12:37:40.966727Z","shell.execute_reply":"2024-04-10T12:37:40.990689Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification\n\nmodel = AutoModelForSequenceClassification.from_pretrained(\"vishnun0027/Text_classification_model_10042024\")\nwith torch.no_grad():\n    logits = model(**inputs).logits","metadata":{"execution":{"iopub.status.busy":"2024-04-10T12:37:40.993871Z","iopub.execute_input":"2024-04-10T12:37:40.994163Z","iopub.status.idle":"2024-04-10T12:37:41.246858Z","shell.execute_reply.started":"2024-04-10T12:37:40.994140Z","shell.execute_reply":"2024-04-10T12:37:41.245685Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"predicted_class_id = logits.argmax().item()\nmodel.config.id2label[predicted_class_id]","metadata":{"execution":{"iopub.status.busy":"2024-04-10T12:37:41.248287Z","iopub.execute_input":"2024-04-10T12:37:41.249467Z","iopub.status.idle":"2024-04-10T12:37:41.260615Z","shell.execute_reply.started":"2024-04-10T12:37:41.249431Z","shell.execute_reply":"2024-04-10T12:37:41.259235Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"'POSITIVE'"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}